---
title: Semantic Search with AWS Bedrock Embeddings
description: This guide will walk you through the process of setting up Meilisearch with AWS Bedrock embeddings to enable semantic search capabilities.
---

## Introduction

This guide will walk you through the process of setting up Meilisearch with AWS Bedrock embeddings to enable semantic search capabilities. By leveraging Meilisearch's AI features and AWS Bedrock's embedding API, you can enhance your search experience and retrieve more relevant results.

## Requirements

To follow this guide, you'll need:

- A [Meilisearch Cloud](https://www.meilisearch.com/cloud) project running version >=1.13
- An AWS account with Bedrock access and an API key for embedding generation. You can sign up for an AWS account at [AWS](https://aws.amazon.com/).

## Setting up Meilisearch

To set up an embedder in Meilisearch, you need to configure it to your settings. You can refer to the [Meilisearch documentation](/reference/api/settings) for more details on updating the embedder settings.

### Text embeddings

AWS Bedrock offers multiple text embedding models:

- `amazon.titan-embed-text-v2:0`: 256, 512, or 1024 dimensions (Amazon Titan Text Embeddings V2)
- `amazon.nova-2-multimodal-embeddings-v1:0`: 256, 384, 1024, or 3072 dimensions (Amazon Nova Multimodal Embeddings - also supports images, video, and audio)
- `cohere.embed-multilingual-v3`: 1024 dimensions (Cohere Embed Multilingual v3)
- `cohere.embed-v4:0`: 256, 512, 1024, or 1536 dimensions (Cohere Embed v4 - also supports images)

**Amazon Titan Text Embeddings V2**

```json
{
  "bedrock": {
    "source": "rest",
    "url": "https://bedrock-runtime.<region>.amazonaws.com/model/amazon.titan-embed-text-v2:0/invoke",
    "apiKey": "<Your Bedrock API Key>",
    "dimensions": 1024,
    "documentTemplate": "<Custom template (Optional, but recommended)>",
    "request": {
      "inputText": "{{text}}",
      "dimensions": 1024,
      "normalize": true
    },
    "response": {
      "embedding": "{{embedding}}"
    }
  }
}
```

**Amazon Nova Multimodal Embeddings (text mode)**

For advanced configuration options like `embeddingPurpose` and `truncationMode`, refer to the [Nova Embeddings schema documentation](https://docs.aws.amazon.com/nova/latest/userguide/embeddings-schema.html).

```json
{
  "bedrock": {
    "source": "rest",
    "url": "https://bedrock-runtime.<region>.amazonaws.com/model/amazon.nova-2-multimodal-embeddings-v1:0/invoke",
    "apiKey": "<Your Bedrock API Key>",
    "dimensions": 1024,
    "documentTemplate": "<Custom template (Optional, but recommended)>",
    "request": {
      "taskType": "SINGLE_EMBEDDING",
      "singleEmbeddingParams": {
        "embeddingPurpose": "GENERIC_INDEX",
        "embeddingDimension": 1024,
        "text": {
          "truncationMode": "END",
          "value": "{{text}}"
        }
      }
    },
    "response": {
      "embeddings": [{ "embedding": "{{embedding}}" }]
    }
  }
}
```

**Cohere Embed Multilingual v3**

```json
{
  "bedrock": {
    "source": "rest",
    "url": "https://bedrock-runtime.<region>.amazonaws.com/model/cohere.embed-multilingual-v3/invoke",
    "apiKey": "<Your Bedrock API Key>",
    "dimensions": 1024,
    "documentTemplate": "<Custom template (Optional, but recommended)>",
    "request": {
      "texts": ["{{text}}"],
      "input_type": "search_document"
    },
    "response": {
      "embeddings": ["{{embedding}}"]
    }
  }
}
```

**Cohere Embed v4 (text mode)**

```json
{
  "bedrock": {
    "source": "rest",
    "url": "https://bedrock-runtime.<region>.amazonaws.com/model/cohere.embed-v4:0/invoke",
    "apiKey": "<Your Bedrock API Key>",
    "dimensions": 1536,
    "documentTemplate": "<Custom template (Optional, but recommended)>",
    "request": {
      "texts": ["{{text}}"],
      "input_type": "search_document"
    },
    "response": {
      "embeddings": { "float": ["{{embedding}}"] }
    }
  }
}
```

In these configurations:

- `source`: Specifies the source of the embedder, which is set to "rest" for using a REST API.
- `url`: The Bedrock Runtime API endpoint. Replace `<region>` with your AWS region (e.g., `us-east-1`, `us-west-2`, `eu-west-3`). Note: Nova is currently only available in `us-east-1`.
- `apiKey`: Replace `<Your Bedrock API Key>` with your actual Bedrock API key.
- `dimensions`: Specifies the dimensions of the embeddings. Titan V2 supports 256, 512, or 1024. Nova supports 256, 384, 1024, or 3072. Cohere v3 outputs 1024 dimensions. Cohere v4 defaults to 1536 dimensions (also supports 256, 512, or 1024 via `output_dimension` parameter).
- `documentTemplate`: Optionally, you can provide a [custom template](/learn/ai_powered_search/getting_started_with_ai_search) for generating embeddings from your documents.
- `request`: Defines the request structure for the Bedrock API. Titan V2 uses `inputText` with optional `dimensions` and `normalize` parameters. Nova uses `taskType`, `singleEmbeddingParams` with `embeddingPurpose`, `embeddingDimension`, and `text` object. Cohere v3 uses `texts` array and `input_type`.
- `response`: Defines the expected response structure from the Bedrock API.

### Multimodal embeddings

AWS Bedrock offers multimodal embedding models for image search capabilities:

- `amazon.titan-embed-image-v1`: 256, 384, or 1024 dimensions (Amazon Titan Multimodal Embeddings G1)
- `amazon.nova-2-multimodal-embeddings-v1:0`: 256, 384, 1024, or 3072 dimensions (Amazon Nova Multimodal Embeddings - supports text, images, video, and audio)
- `cohere.embed-v4:0`: 256, 512, 1024, or 1536 dimensions (Cohere Embed v4 - supports text, images, and interleaved texts and images)

These models require `indexingFragments` and `searchFragments` because they embed images during indexing and text queries during search.

**Amazon Titan Multimodal Embeddings G1**

```json
{
  "bedrock": {
    "source": "rest",
    "url": "https://bedrock-runtime.<region>.amazonaws.com/model/amazon.titan-embed-image-v1/invoke",
    "apiKey": "<Your Bedrock API Key>",
    "dimensions": 1024,
    "indexingFragments": {
      "image": {
        "value": {
          "inputImage": "{{doc.image_base64}}",
          "embeddingConfig": {
            "outputEmbeddingLength": 1024
          }
        }
      }
    },
    "searchFragments": {
      "text": {
        "value": {
          "inputText": "{{q}}",
          "embeddingConfig": {
            "outputEmbeddingLength": 1024
          }
        }
      }
    },
    "request": "{{fragment}}",
    "response": {
      "embedding": "{{embedding}}"
    }
  }
}
```

**Amazon Nova Multimodal Embeddings (image mode)**

For complete configuration options like `embeddingPurpose`, `detailLevel`, and supported formats, refer to the [Nova Embeddings schema documentation](https://docs.aws.amazon.com/nova/latest/userguide/embeddings-schema.html).

```json
{
  "bedrock": {
    "source": "rest",
    "url": "https://bedrock-runtime.<region>.amazonaws.com/model/amazon.nova-2-multimodal-embeddings-v1:0/invoke",
    "apiKey": "<Your Bedrock API Key>",
    "dimensions": 1024,
    "indexingFragments": {
      "image": {
        "value": {
          "taskType": "SINGLE_EMBEDDING",
          "singleEmbeddingParams": {
            "embeddingPurpose": "GENERIC_INDEX",
            "embeddingDimension": 1024,
            "image": {
              "format": "<png|jpeg|gif|webp>",
              "source": {
                "bytes": "{{doc.image_base64}}"
              }
            }
          }
        }
      }
    },
    "searchFragments": {
      "text": {
        "value": {
          "taskType": "SINGLE_EMBEDDING",
          "singleEmbeddingParams": {
            "embeddingPurpose": "GENERIC_RETRIEVAL",
            "embeddingDimension": 1024,
            "text": {
              "truncationMode": "END",
              "value": "{{q}}"
            }
          }
        }
      }
    },
    "request": "{{fragment}}",
    "response": {
      "embeddings": [{ "embedding": "{{embedding}}" }]
    }
  }
}
```

**Cohere Embed v4**

```json
{
  "bedrock": {
    "source": "rest",
    "url": "https://bedrock-runtime.<region>.amazonaws.com/model/cohere.embed-v4:0/invoke",
    "apiKey": "<Your Bedrock API Key>",
    "dimensions": 1536,
    "indexingFragments": {
      "image": {
        "value": {
          "images": ["data:image/jpeg;base64,{{doc.image_base64}}"],
          "input_type": "search_document"
        }
      }
    },
    "searchFragments": {
      "text": {
        "value": {
          "texts": ["{{q}}"],
          "input_type": "search_query"
        }
      }
    },
    "request": "{{fragment}}",
    "response": {
      "embeddings": { "float": ["{{embedding}}"] }
    }
  }
}
```

In these configurations:

- `source`: Specifies the source of the embedder, which is set to "rest" for using a REST API.
- `url`: The Bedrock Runtime API endpoint. Replace `<region>` with your AWS region (e.g., `us-east-1`, `us-west-2`, `eu-west-3`).
- `apiKey`: Replace `<Your Bedrock API Key>` with your actual Bedrock API key.
- `dimensions`: Specifies the dimensions of the embeddings. Titan Multimodal supports 256, 384, or 1024. Nova supports 256, 384, 1024, or 3072. Cohere v4 supports 256, 512, 1024, or 1536.
- `indexingFragments`: Defines how to embed images during document indexing. Uses `{{doc.FIELD_NAME}}` to reference the base64-encoded image field in your documents (e.g., `{{doc.image_base64}}`).
- `searchFragments`: Defines how to embed text during search queries. Uses `{{q}}` to reference the search query.
- `request`: Set to `{{fragment}}` to use the appropriate fragment based on the operation.
- `response`: Defines the expected response structure from the Bedrock API.

Once you've configured the embedder settings, Meilisearch will automatically generate embeddings for your documents and store them in the vector store.

Please note that AWS Bedrock has rate limiting, which is managed by Meilisearch. The indexation process may take some time depending on your AWS account limits, but Meilisearch will handle it with a retry strategy.

It's recommended to monitor the tasks queue to ensure everything is running smoothly. You can access the tasks queue using the Cloud UI or the [Meilisearch API](/reference/api/tasks).

## Testing semantic search

With the embedder set up, you can now perform semantic searches using Meilisearch. When you send a search query, Meilisearch will generate an embedding for the query using the configured embedder and then use it to find the most semantically similar documents in the vector store.

To perform a semantic search, you simply need to make a normal search request but include the hybrid parameter:

```json
{
  "q": "<Query made by the user>",
  "hybrid": {
    "semanticRatio": 1,
    "embedder": "bedrock"
  }
}
```

In this request:

- `q`: Represents the user's search query.
- `hybrid`: Specifies the configuration for the hybrid search.
  - `semanticRatio`: Allows you to control the balance between semantic search and traditional search. A value of 1 indicates pure semantic search, while a value of 0 represents full-text search. You can adjust this parameter to achieve a hybrid search experience.
  - `embedder`: The name of the embedder used for generating embeddings. Make sure to use the same name as specified in the embedder configuration, which in this case is "bedrock".

You can use the Meilisearch API or client libraries to perform searches and retrieve the relevant documents based on semantic similarity.

## Conclusion

By following this guide, you should now have Meilisearch set up with AWS Bedrock embedding, enabling you to leverage semantic search capabilities in your application. Meilisearch's auto-batching and efficient handling of embeddings make it a powerful choice for integrating semantic search into your project.

To explore further configuration options for embedders, consult the [detailed documentation about the embedder setting possibilities](/reference/api/settings).
