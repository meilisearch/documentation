---
title: Semantic Search with Hugging Face Inference Endpoints - Meilisearch documentation
description: This guide will walk you through the process of setting up Meilisearch with Hugging Face Inference Endpoints.
---

# Semantic search with Hugging Face Inference Endpoints

## Introduction

This guide will walk you through the process of setting up a Meilisearch REST embedder with [Hugging Face Inference Endpoints](https://ui.endpoints.huggingface.co/) to enable semantic search capabilities.

<Capsule intent="note" title="`rest` or `huggingface`?">
You can use Hugging Face and Meilisearch in two ways: running the model locally by setting the embedder source to `huggingface`, or remotely in Hugging Face's servers by setting the embeder source to `rest`.
</Capsule>

## Requirements

To follow this guide, you'll need:

- A [Meilisearch Cloud](https://www.meilisearch.com/cloud) project running version 1.10 or above with the Vector store activated
- A [Hugging Face account](https://huggingface.co/) with a deployed inference endpoint
- The endpoint URL and API key of the deployed model on your Hugging Face account

## Configure the embedder

Set up an embedder using the update settings endpoint:

```json
{
  "hf-inference": {
    "source": "rest",
    "url": "ENDPOINT_URL",
    "apiKey": "API_KEY",
    "dimensions": 384,
    "documentTemplate": "CUSTOM_LIQUID_TEMPLATE",
    "request": {
      "inputs": ["{{text}}", "{{..}}"],
      "model": "baai/bge-small-en-v1.5"
    },
    "response": ["{{embedding}}", "{{..}}"]
  }
}
```

In this configuration:

- `source`: declares Meilisearch should connect to this embedder via its REST API
- `url`: replace `ENDPOINT_URL` with the address of your Hugging Face model endpoint
- `apiKey`: replace `API_KEY` with your Hugging Face API key
- `dimensions`: specifies the dimensions of the embeddings, which are 384 for `baai/bge-small-en-v1.5`
- `documentTemplate`: an optional but recommended [template](/learn/ai_powered_search/getting_started_with_ai_search) for the data you will send the embedder
- `request`: defines the structure and parameters of the request Meilisearch will send to the embedder
- `response`: defines the structure of the embedder's  response

Once you've configured the embedder, Meilisearch will automatically generate embeddings for your documents. Monitor the task using the Cloud UI or the [get task endpoint](/reference/api/tasks).

<Capsule intent="note">
This example uses [BAAI/bge-small-en-v1.5](https://huggingface.co/BAAI/bge-small-en-v1.5) as its model, but Hugging Face offers [other options that may fit your dataset better](https://ui.endpoints.huggingface.co/catalog?task=sentence-embeddings).
</Capsule>

## Perform a semantic search

With the embedder set up, you can now perform semantic searches. Make a search request with the `hybrid` search parameter, setting `semanticRatio` to `1`:

```json
{
  "q": "QUERY_TERMS",
  "hybrid": {
    "semanticRatio": 1,
    "embedder": "hf-inference"
  }
}
```

In this request:

- `q`: the search query
- `hybrid`: enables AI-powered search functionality
  - `semanticRatio`: controls the balance between semantic search and full-text search. Setting it to `1` means you will only receive semantic search results
  - `embedder`: the name of the embedder used for generating embeddings

## Conclusion

You have set up with an embedder using Hugging Face Inference Endpoints. This allows you to use pure semantic search capabilities in your application.

Consult the [embedder setting documentation](/reference/api/settings#embedders-experimental) for more information on other embedder configuration options.
