---
title: Getting started with conversational search
description: This guide walks you through implementing Meilisearch's chat completions feature to create conversational search experiences in your application
---

Chat completions have three key components: index integration, workspace configuration, and the chat interface.

operate through workspaces, which are isolated configurations for different use cases. Each workspace can:

- Use different LLM sources (openAi, azureOpenAi, mistral, gemini, vLlm)
- Apply custom prompts
- Access specific indexes based on API keys
- Maintain separate conversation contexts

### Key components

1. **Chat endpoint**: `/chats/{workspace}/chat/completions`
   - OpenAI-compatible interface
   - Supports streaming responses
   - Handles tool calling for index searches

2. **Workspace settings**: `/chats/{workspace}/settings`
   - Configure LLM provider and model
   - Set system prompts
   - Manage API credentials

3. **Index integration**:
   - Automatically searches relevant indexes
   - Uses existing Meilisearch search capabilities
   - Respects API key permissions

## Prerequisites

Before starting, ensure you have:

- A [secure](/learn/security/basic_security) Meilisearch >= v1.15.1 project
- An API key from an LLM provider
- At least one index with searchable content

## Setup

### Enable the chat completions feature

First, enable the chat completions experimental feature:

```bash
curl \
  -X PATCH 'http://localhost:7700/experimental-features/' \
  -H 'Authorization: Bearer MEILISEARCH_KEY' \
  -H 'Content-Type: application/json' \
  --data-binary '{
    "chatCompletions": true
  }'
```

### Find your chat API key

When Meilisearch runs with a master key on an instance created after v1.15.1, it automatically generates a "Default Chat API Key" with `chatCompletions` and `search` permissions on all indexes. Check if you have the key using:

```bash
curl http://localhost:7700/keys \
  -H "Authorization: Bearer MEILISEARCH_KEY"
```

Look for the key with the description "Default Chat API Key" Use this key when querying the `/chats` endpoint.

#### Troubleshooting: Missing default chat API key

If your instance does not have a Default Chat API Key, create one manually:

```bash
curl \
  -X POST 'http://localhost:7700/keys' \
  -H 'Authorization: Bearer MEILISEARCH_KEY' \
  -H 'Content-Type: application/json' \
  --data-binary '{
    "name": "Chat API Key",
    "description": "API key for chat completions",
    "actions": ["search", "chatCompletions"],
    "indexes": ["*"],
    "expiresAt": null
  }'
```

## Configure your indexes for chat

After activating the `/chats` route and obtaining an API key with chat access, you must configure the indexes your conversational interface has access to.

Configure the `chat` settings for each index you want to be searchable via chat UI:

```bash
curl \
  -X PATCH 'http://localhost:7700/indexes/INDEX_NAME/settings' \
  -H 'Authorization: Bearer MEILISEARCH_KEY' \
  -H 'Content-Type: application/json' \
  --data-binary '{
    "chat": {
      "description": "A comprehensive database of TYPE_OF_DOCUMENT containing titles, descriptions, genres, and release dates to help users searching for TYPE_OF_DOCUMENT",
      "documentTemplate": "{% for field in fields %}{% if field.is_searchable and field.value != nil %}{{ field.name }}: {{ field.value }}\n{% endif %}{% endfor %}",
      "documentTemplateMaxBytes": 400
    }
  }'
```

- `description` gives the initial context of the conversation to the LLM. A good description improves relevance of the chat's answers
- `documentTemplate` defines which document fields Meilisearch will send the AI provider. Consult the best [document template best practices](/learn/ai_powered_search/document_template_best_practices) article for more guidance

## Configure a chat completions workspace

The next step is to create a workspace. Chat completion workspaces are isolated configurations targeting  different use cases. For example, you may have one workspace for publicly visible data, and another for data only available for logged in users.

Create a workspace setting your LLM provider as its `source`:

<CodeGroup>

```bash openAi
curl \
  -X PATCH 'http://localhost:7700/chats/WORKSPACE_NAME/settings' \
  -H 'Authorization: Bearer MEILISEARCH_KEY' \
  -H 'Content-Type: application/json' \
  --data-binary '{
    "source": "openAi",
    "apiKey": "PROVIDER_API_KEY",
    "baseUrl": "PROVIDER_API_URL",
    "prompts": {
      "system": "You are a helpful assistant. Answer questions based only on the provided context."
    }
  }'
```

```bash azureOpenAi
curl \
  -X PATCH 'http://localhost:7700/chats/WORKSPACE_NAME/settings' \
  -H 'Authorization: Bearer MEILISEARCH_KEY' \
  -H 'Content-Type: application/json' \
  --data-binary '{
    "source": "azureOpenAi",
    "apiKey": "PROVIDER_API_KEY",
    "baseUrl": "PROVIDER_API_URL",
    "prompts": {
      "system": "You are a helpful assistant. Answer questions based only on the provided context."
    }
  }'
```

```bash mistral
curl \
  -X PATCH 'http://localhost:7700/chats/WORKSPACE_NAME/settings' \
  -H 'Authorization: Bearer MEILISEARCH_KEY' \
  -H 'Content-Type: application/json' \
  --data-binary '{
    "source": "mistral",
    "apiKey": "PROVIDER_API_KEY",
    "prompts": {
      "system": "You are a helpful assistant. Answer questions based only on the provided context."
    }
  }'
```

```bash gemini
curl \
  -X PATCH 'http://localhost:7700/chats/WORKSPACE_NAME/settings' \
  -H 'Authorization: Bearer MEILISEARCH_KEY' \
  -H 'Content-Type: application/json' \
  --data-binary '{
    "source": "gemini",
    "apiKey": "PROVIDER_API_KEY",
    "prompts": {
      "system": "You are a helpful assistant. Answer questions based only on the provided context."
    }
  }'
```

```bash vLlm
curl \
  -X PATCH 'http://localhost:7700/chats/WORKSPACE_NAME/settings' \
  -H 'Authorization: Bearer MEILISEARCH_KEY' \
  -H 'Content-Type: application/json' \
  --data-binary '{
    "source": "vLlm",
    "baseUrl": "PROVIDER_API_URL",
    "prompts": {
      "system": "You are a helpful assistant. Answer questions based only on the provided context."
    }
  }'
```

</CodeGroup>

Which fields are mandatory will depend on your chosen provider `source`. In most cases, you will have to provide an `apiKey` to access the provider.

`baseUrl` indicates the URL Meilisearch queries when users submit questions to your chat interface.

`prompts.system` gives the conversational search bot the baseline context of your users and their questions.

## Send your first chat completions request

You have finished configuring your conversational search agent. Use `curl` in your terminal to confirm everything is working. Sending a streaming query to the chat completions API route:

```bash
curl -N \
  -X POST 'http://localhost:7700/chats/WORKSPACE_NAME/chat/completions' \
  -H 'Authorization: Bearer MEILISEARCH_API_KEY' \
  -H 'Content-Type: application/json' \
  --data-binary '{
    "model": "PROVIDER_MODEL_UID",
    "messages": [
      {
        "role": "user",
        "content": "USER_PROMPT"
      }
    ],
    "tools": [
      {
        "type": "function",
        "function": {
          "name": "_meiliSearchProgress",
          "description": "Reports real-time search progress to the user"
        }
      },
      {
        "type": "function",
        "function": {
          "name": "_meiliSearchSources",
          "description": "Provides sources and references for the information"
        }
      }
    ]
  }'
```

- `model` is mandatory and must indicate a model supported by your chosen `source`
- `messages` contains the messages exchanged between the conversational search agent and the user
- `tools` sets up two optional but highly [recommended tools](/learn/chat/chat_tooling_reference):
  - `_meiliSearchProgress`: shows users what searches are being performed
  - `_meiliSearchSources`: displays the actual documents used to generate responses

If Meilisearch returns a stream of data containing the chat agent response, you have correctly configured Meilisearch for conversational search:

```sh
data: {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1677652288,"model":"gpt-3.5-turbo","choices":[{"index":0,"delta":{"content":"Meilisearch"},"finish_reason":null}]}
```

If Meilisearch returns an error, consult the [troubleshooting section](#troubleshooting) to understand diagnose and fix the issues you encountered.

## Next steps

In this article, you have seen how to activate the chats completion route, prepare your indexes to serve as a base for your AI agent, and performed your first conversational search.

In most cases, that is only the beginning of adding conversational search to your application. Next, you are most likely going to want to add a graphical user interface to your application.

### Building a chat interface using the OpenAI SDK

Creating a full chat interface is out of scope for this tutorial, but here is one important tip.

Meilisearch's chat endpoint was designed to be OpenAI-compatible. This means you can use the official OpenAI SDK in any supported programming language, even if your provider is not OpenAI:

<CodeGroup>

```javascript JavaScript
import OpenAI from 'openai';

const client = new OpenAI({
  baseURL: 'http://localhost:7700/chats/WORKSPACE_NAME',
  apiKey: 'PROVIDER_API_KEY',
});

const completion = await client.chat.completions.create({
  model: 'PROVIDER_MODEL_UID',
  messages: [{ role: 'user', content: 'USER_PROMPT' }]
});

for await (const chunk of completion) {
  console.log(chunk.choices[0]?.delta?.content || '');
}
```

```python Python
from openai import OpenAI

client = OpenAI(
    base_url="http://localhost:7700/chats/WORKSPACE_NAME",
    api_key="YOUR_CHAT_API_KEY"
)

stream = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[{"role": "user", "content": "USER_PROMPT"}]
)

for chunk in stream:
    if chunk.choices[0].delta.content is not None:
        print(chunk.choices[0].delta.content, end="")
```

```typescript TypeScript
import OpenAI from 'openai';

const client = new OpenAI({
  baseURL: 'http://localhost:7700/chats/WORKSPACE_NAME',
  apiKey: 'YOUR_CHAT_API_KEY',
});

const stream = await client.chat.completions.create({
  model: 'gpt-3.5-turbo',
  messages: [{ role: 'user', content: 'USER_PROMPT' }]
});

for await (const chunk of stream) {
  const content = chunk.choices[0]?.delta?.content || '';
  process.stdout.write(content);
}
```

</CodeGroup>

### Error handling

Use the OpenAI SDK's built-in functionality to handle errors without additional configuration:

<CodeGroup>

```javascript JavaScript
import OpenAI from 'openai';

const client = new OpenAI({
  baseURL: 'http://localhost:7700/chats/WORKSPACE_NAME',
  apiKey: 'MEILISEARCH_KEY',
});

try {
  const stream = await client.chat.completions.create({
    model: 'gpt-3.5-turbo',
    messages: [{ role: 'user', content: 'What is Meilisearch?' }],
    stream: true,
  });

  for await (const chunk of stream) {
    console.log(chunk.choices[0]?.delta?.content || '');
  }
} catch (error) {
  // OpenAI SDK automatically handles streaming errors
  console.error('Chat completion error:', error);
}
```

```python Python
from openai import OpenAI

client = OpenAI(
    base_url="http://localhost:7700/chats/WORKSPACE_NAME",
    api_key="MEILISEARCH_KEY"
)

try:
    stream = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": "What is Meilisearch?"}],
        stream=True,
    )

    for chunk in stream:
        if chunk.choices[0].delta.content is not None:
            print(chunk.choices[0].delta.content, end="")
except Exception as error:
    # OpenAI SDK automatically handles streaming errors
    print(f"Chat completion error: {error}")
```

</CodeGroup>

## Troubleshooting

### Common issues and solutions

#### Empty reply from server (curl error 52)

**Causes:**

- Meilisearch not started with a master key
- Experimental features not enabled
- Missing authentication in requests

**Solution:**

1. Restart Meilisearch with a master key: `meilisearch --master-key yourKey`
2. Enable experimental features (see setup instructions above)
3. Include Authorization header in all requests

#### "Invalid API key" error

**Cause:** Using the wrong type of API key

**Solution:**

- Use either the master key or the "Default Chat API Key"
- Don't use search or admin API keys for chat endpoints
- Find your chat key: `curl http://localhost:7700/keys -H "Authorization: Bearer MEILISEARCH_KEY"`

#### "Socket connection closed unexpectedly"

**Cause:** Usually means the OpenAI API key is missing or invalid in workspace settings

**Solution:**

1. Check workspace configuration:

   ```bash
   curl http://localhost:7700/chats/WORKSPACE_NAME/settings \
     -H "Authorization: Bearer MEILISEARCH_KEY"
   ```

2. Update with valid API key:

   ```bash
   curl -X PATCH http://localhost:7700/chats/WORKSPACE_NAME/settings \
     -H "Authorization: Bearer MEILISEARCH_KEY" \
     -H "Content-Type: application/json" \
     -d '{"apiKey": "your-valid-api-key"}'
   ```

#### Chat not searching the database

**Cause:** Missing Meilisearch tools in the request

**Solution:**

- Include `_meiliSearchProgress` and `_meiliSearchSources` tools in your request
- Ensure indexes have proper chat descriptions configured
