---
title: Vector search â€” Meilisearch documentation
description: Vector search is an experimental technology that uses Large Language Models to retrieve search results. This feature is useful when you are interested in results based on the meaning and context of a query.
---

# Vector search

[Vector search](https://meilisearch.com/solutions/vector-search?utm_campaign=vector-search&utm_source=docs) is an experimental technology that uses Large Language Models to retrieve search results based on the meaning and context of a query.

This feature can improve search relevancy for queries that do not to match keywords in your dataset, allow your users to search images and other non-textual media, suggest related products in webshops, and create conversational search interfaces.

Vector search is available to all users. [Meilisearch Cloud](https://www.meilisearch.com/cloud?utm_campaign=vector-search&utm_source=docs) is the recommended way of using vector search.

## Using vector search

### Activate vector search

If using Meilisearch Cloud, navigate to your project overview and find "Experimental features", then check the "vector store" box.

![A section of the project overview interface titled "Experimental features". There are two options: "Score details" and "Vector store". "Vector store" is turned on.](https://raw.githubusercontent.com/meilisearch/documentation/main/assets/images/vector-search/01-cloud-vector-store.png)

Alternatively, use [the `/experimental` route](/reference/api/experimental_features) to activate vector search during runtime:

```sh
curl \
  -X PATCH 'http://localhost:7700/experimental-features/' \
  -H 'Content-Type: application/json'  \
  --data-binary '{
    "vectorStore": true
  }'
```

### Generate vector embeddings

To use vector search, first configure the `embedders` index setting. You may configure multiple embedders for an index. 

Embedders generate vector data from your documents. Meilisearch natively supports [OpenAI](https://openai.com/) and [HuggingFace](https://huggingface.co/) embedders. 

It is also possible to use custom embedders. In this case, you must generate the embeddings manually and add include them as a field in your documents.

#### Generate auto-embeddings with OpenAI 

Use the `embedders` index setting of the [update `/settings` endpoint](/reference/api/settings) to configure one or more embedders for an index:

```sh
curl \
  -X PATCH 'http://localhost:7700/indexes/movies/settings' \
  -H 'Content-Type: application/json' \
  --data-binary '{
    "embedders": {
      "default": {
        "source":  "openAI",
        "apiKey": "anOpenAiApiKey",
        "model": "text-embedding-ada-002",
        "documentTemplate": "A movie titled '{{doc.title}}' whose description starts with {{doc.overview|truncatewords: 20}}"
      }
    }
  }'
```

`documentTemplate` is an optional field you can use to send only relevant data to the model. `documentTemplate` must be a [Liquid template](https://shopify.github.io/liquid/).

#### Generate auto-embeddings with HuggingFace 

Use the `embedders` index setting of the [update `/settings` endpoint](/reference/api/settings) to configure one or more embedders for an index:

```sh
curl \
  -X PATCH 'http://localhost:7700/indexes/movies/settings' \
  -H 'Content-Type: application/json' \
  --data-binary '{
    "embedders": {
      "default": {
        "source":  "huggingFace",
        "model": "bge-base-en-v1.5",
        "documentTemplate": "A movie titled '{{doc.title}}' whose description starts with {{doc.overview|truncatewords: 20}}"
      }
    }
  }'
```

`documentTemplate` is an optional field you can use to send only relevant data to the model. `documentTemplate` must be a [Liquid template](https://shopify.github.io/liquid/).

<Capsule intent="note">
The HuggingFace computes embedders locally. This is a resource-intensive operation and might affect performance.
</Capsule>

#### Custom embeddings

You may also provide custom embeddings. In this case, you must manually update your embeddings when adding, updating, and removing documents to your index.

Configure the `embedder` index setting:

```sh
curl \
  -X PATCH 'http://localhost:7700/indexes/movies/settings' \
  -H 'Content-Type: application/json' \
  --data-binary '{
    "embedders": {
      "default": {
        "source":  "userProvided",
        "dimensions": 3
      }
    }
  }'
```

Then, use [the `/documents` endpoint](/reference/api/documents) to upload vectorized documents. Store vector data in your documents' `_vector` field:

```sh
curl -X POST -H 'content-type: application/json' \
'localhost:7700/indexes/products/documents' \
--data-binary '[
    { "id": 0, "_vectors": {"image2text": [0, 0.8, -0.2]}, "text": "frying pan" },
    { "id": 1, "_vectors": {"image2text": [1, -0.2, 0]}, "text": "baking dish" }
]'
```

### Vector search with auto-embeddings

Perform searches with `q` and `hybrid` to retrieve search results using both keyword and semantic search:

```sh
curl -X POST -H 'content-type: application/json' \
  'localhost:7700/indexes/products/search' \
  --data-binary '{ 
    "q": "kitchen utensils",
    "hybrid": {
      "semanticRatio": 0.9,
      "embedder": "default"
    }
  }'
```

`hybrid` is an object and accepts two fields:
- `semanticRatio`: number between `0` and `1`. `0` indicates full keyword search, `1` indicates full semantic search. Defaults to `0.5`
- `embedder`: string, indicating one of the embedders configured for the queried index. Defaults to `"default"`

`hybrid` can be used together with [other search parameters](/reference/api/search), including [`filter`](/reference/api/search#filter) and [`sort`](/reference/api/search#sort):

```sh
curl -X POST -H 'content-type: application/json' \
  'localhost:7700/indexes/products/search' \
  --data-binary '{
    "q": "kitchen utensils",
    "hybrid": {
      "semanticRatio": 0.9,
      "embedder": "default"
    },
    "filter": "price < 10",
    "sort": ["price:asc"]
  }'
```

### Vector search with user-provided embeddings

Use the `vector` search parameter to perform vector searches: 

```sh
curl -X POST -H 'content-type: application/json' \
  'localhost:7700/indexes/products/search' \
  --data-binary '{ "vector": [0, 1, 2] }'
```

`vector` must be an array of numbers indicating the search vector. You must generate these yourself when using vector search with user-provided embeddings.

`vector` can be used together with [other search parameters](/reference/api/search), including [`filter`](/reference/api/search#filter) and [`sort`](/reference/api/search#sort):

```sh
curl -X POST -H 'content-type: application/json' \
  'localhost:7700/indexes/products/search' \
  --data-binary '{
    "vector": [0, 1, 2],
    "filter": "price < 10",
    "sort": ["price:asc"]
  }'
```

<Capsule intent="tip" title="Other resources">
Check out the Meilisearch blog post for a [tutorial on implementing semantic search with LangChain](https://blog.meilisearch.com/langchain-semantic-search-tutorial/?utm_campaign=vector-search&utm_source=docs).
</Capsule>

## More information

Consult the [feature discussion on GitHub](https://github.com/orgs/meilisearch/discussions/621) for the latest information on using vector search with Meilisearch. This feature is undergoing active development and any feedback you might have is welcome.
