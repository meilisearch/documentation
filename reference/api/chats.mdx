---
title: Chats
sidebarTitle: Chats
description: Use the chat completion API to create conversational search experiences using LLM technology
---

import { RouteHighlighter } from '/snippets/route_highlighter.mdx';

The `/chats` route enables AI-powered conversational search by integrating Large Language Models (LLMs) with your Meilisearch data.

<Note>
This is an experimental feature. Use the Meilisearch Cloud UI or the experimental features endpoint to activate it:

```sh
curl \
  -X PATCH 'MEILISEARCH_URL/experimental-features/' \
  -H 'Content-Type: application/json' \
  --data-binary '{
    "chatCompletions": true
  }'
```
</Note>

## Authorization

When working with a secure Meilisearch instance, Use an API key with access to both the `search` and `chatCompletions` actions, such as the default chat API key. You may also use tenant tokens instead of an API key, provided you generate the tokens with access to the required actions.

Chat queries only search indexes its API key can access. The default chat API key has access to all indexes. To limit chat access to specific indexes, you must either create a new key, or [generate a tenant token](/learn/security/generate_tenant_token_sdk) from the default chat API key.

LLM credentials used to querying your AI provider are stored securely in the chat workspace settings.

## Chat workspace object

```json
{
  "uid": "WORKSPACE_NAME"
}
```

| Name        | Type   | Description                                          |
| :---------- | :----- | :--------------------------------------------------- |
| **`uid`**   | String | Unique identifier for the chat completions workspace |

## List chat workspaces

<RouteHighlighter method="GET" path="/chats" />

List all chat workspaces. Results can be paginated by using the `offset` and `limit` query parameters.

### Query parameters

| Query parameter | Description                    | Default value |
| :-------------- | :----------------------------- | :------------ |
| **`offset`**    | Number of workspaces to skip   | `0`           |
| **`limit`**     | Number of workspaces to return | `20`          |

### Response

| Name          | Type    | Description                          |
| :------------ | :------ | :----------------------------------- |
| **`results`** | Array   | An array of [workspaces](#chat-workspace-object) |
| **`offset`**  | Integer | Number of workspaces skipped            |
| **`limit`**   | Integer | Number of workspaces returned           |
| **`total`**   | Integer | Total number of workspaces              |

### Example

```sh
  curl \
    -X GET 'MEILISEARCH_URL/chats?limit=3'
```

#### Response: `200 Ok`

```json
{
  "results": [
    { "uid": "WORKSPACE_1" },
    { "uid": "WORKSPACE_2" },
    { "uid": "WORKSPACE_3" }
  ],
  "offset": 0,
  "limit": 20,
  "total": 3
}
```

## Get one chat workspace

<RouteHighlighter method="GET" path="/chats/{workspace_uid}" />

Get information about a workshop.

### Path parameters

| Name              | Type   | Description                                                               |
| :---------------- | :----- | :------------------------------------------------------------------------ |
| **`workspace_uid`** * | String | `uid` of the requested index |

### Example

```sh
  curl \
    -X GET 'MEILISEARCH_URL/chats/WORKSPACE_UID'
```

#### Response: `200 Ok`

```json
{
  "uid": "WORKSPACE_UID"
}
```

## Chat workspace settings

### Chat workspace settings object

```json
{
  "source": "openAi",
  "orgId": null,
  "projectId": null,
  "apiVersion": null,
  "deploymentId": null,
  "baseUrl": null,
  "apiKey": "sk-abc...",
  "prompts": {
    "system": "You are a helpful assistant that answers questions based on the provided context."
  }
}
```

#### The prompts object

| Name                      | Type   | Description                                                       |
| :------------------------ | :----- | :---------------------------------------------------------------- |
| **`system`**              | String | A prompt added to the start of the conversation to guide the LLM  |
| **`searchDescription`**   | String | A prompt to explain what the internal search function does        |
| **`searchQParam`**        | String | A prompt to explain what the `q` parameter of the search function does and how to use it |
| **`searchIndexUidParam`** | String | A prompt to explain what the `indexUid` parameter of the search function does and how to use it |

### Get chat workspace settings

<RouteHighlighter method="GET" path="/chats/{workspace_uid}/settings" />

Retrieve the current settings for a chat workspace.

#### Path parameters

| Name            | Type   | Description                          |
| :-------------- | :----- | :----------------------------------- |
| **`workspace_uid`** | String | The workspace identifier             |

#### Response: `200 OK`

Returns the settings object. For security reasons, the `apiKey` field is obfuscated.

```json
{
  "source": "openAi",
  "prompts": {
    "system": "You are a helpful assistant."
  }
}
```

#### Example

<CodeGroup>

```bash cURL
curl \
  -X GET 'http://localhost:7700/chats/WORKSPACE_UID/settings' \
  -H 'Authorization: Bearer MEILISEARCH_KEY'
```

</CodeGroup>

### Create a chat workspace and update chat workspace settings

<RouteHighlighter method="PATCH" path="/chats/{workspace_uid}/settings" />

Configure the LLM provider and settings for a chat workspace.

If a workspace does not exist, querying this endpoint will create it.

#### Path parameters

| Name            | Type   | Description                          |
| :-------------- | :----- | :----------------------------------- |
| **`workspace_uid`** | String | The workspace identifier             |

#### Settings parameters

| Name              | Type   | Description                                                                   |
| :---------------- | :----- | :---------------------------------------------------------------------------- |
| **`source`**      | String | LLM source: `"openAi"`, `"azureOpenAi"`, `"mistral"`, `"gemini"`, or `"vLlm"` |
| **`orgId`**       | String | Organization ID for the LLM provider (required for azureOpenAi)               |
| **`projectId`**   | String | Project ID for the LLM provider                                               |
| **`apiVersion`**  | String | API version for the LLM provider (required for azureOpenAi)                   |
| **`deploymentId`**| String | Deployment ID for the LLM provider (required for azureOpenAi)                 |
| **`baseUrl`**     | String | Base URL for the provider (required for azureOpenAi and vLlm)                 |
| **`apiKey`**      | String | API key for the LLM provider (optional for vLlm)                              |
| **`prompts`**     | Object | Prompts object containing system prompts and other configuration              |

#### Request body

```json
{
  "source": "openAi",
  "apiKey": "OPEN_AI_API_KEY",
  "prompts": {
    "system": "DEFAULT CHAT INSTRUCTIONS"
  }
}
```

All fields are optional. Only provided fields will be updated.

#### Response: `200 OK`

Returns the updated settings object. `apiKey` is write-only and will not be returned in the response.

#### Examples

<CodeGroup>

```bash openAi
curl \
  -X PATCH 'http://localhost:7700/chats/customer-support/settings' \
  -H 'Authorization: Bearer MEILISEARCH_KEY' \
  -H 'Content-Type: application/json' \
  --data-binary '{
    "source": "openAi",
    "apiKey": "sk-abc...",
    "prompts": {
      "system": "You are a helpful customer support assistant."
    }
  }'
```

```bash azureOpenAi
curl \
  -X PATCH 'http://localhost:7700/chats/customer-support/settings' \
  -H 'Authorization: Bearer MEILISEARCH_KEY' \
  -H 'Content-Type: application/json' \
  --data-binary '{
    "source": "azureOpenAi",
    "orgId": "your-azure-org-id",
    "apiVersion": "your-api-version",
    "deploymentId": "your-deployment-id",
    "apiKey": "your-azure-api-key",
    "baseUrl": "https://your-resource.openai.azure.com",
    "prompts": {
      "system": "You are a helpful customer support assistant."
    }
  }'
```

```bash mistral
curl \
  -X PATCH 'http://localhost:7700/chats/customer-support/settings' \
  -H 'Authorization: Bearer MEILISEARCH_KEY' \
  -H 'Content-Type: application/json' \
  --data-binary '{
    "source": "mistral",
    "apiKey": "your-mistral-api-key",
    "prompts": {
      "system": "You are a helpful customer support assistant."
    }
  }'
```

```bash gemini
curl \
  -X PATCH 'http://localhost:7700/chats/customer-support/settings' \
  -H 'Authorization: Bearer MEILISEARCH_KEY' \
  -H 'Content-Type: application/json' \
  --data-binary '{
    "source": "gemini",
    "apiKey": "your-gemini-api-key",
    "prompts": {
      "system": "You are a helpful customer support assistant."
    }
  }'
```

```bash vLlm
curl \
  -X PATCH 'http://localhost:7700/chats/customer-support/settings' \
  -H 'Authorization: Bearer MEILISEARCH_KEY' \
  -H 'Content-Type: application/json' \
  --data-binary '{
    "source": "vLlm",
    "baseUrl": "http://your-vllm-server:8000",
    "prompts": {
      "system": "You are a helpful customer support assistant."
    }
  }'
```

</CodeGroup>

### Reset chat workspace settings

<RouteHighlighter method="DELETE" path="/chats/{workspace_uid}/settings" />

Reset a chat workspace's settings to its default values.

#### Path parameters

| Name            | Type   | Description                          |
| :-------------- | :----- | :----------------------------------- |
| **`workspace_uid`** | String | The workspace identifier             |

#### Response: `200 OK`

Returns the settings object without the `apiKey` field.

```json
{
  "source": "openAi",
  "prompts": {
    "system": "You are a helpful assistant."
  }
}
```

#### Example

<CodeGroup>

```bash cURL
curl \
  -X DELETE 'http://localhost:7700/chats/customer-support/settings' \
  -H 'Authorization: Bearer MEILISEARCH_KEY'
```

</CodeGroup>

## Chat completions

<RouteHighlighter method="POST" path="/chats/{workspace_uid}/chat/completions" />

Create a chat completion using Meilisearch's OpenAI-compatible interface. The endpoint searches relevant indexes and generates responses based on the retrieved content.

### Path parameters

| Name            | Type   | Description                                           |
| :-------------- | :----- | :---------------------------------------------------- |
| **`workspace`** | String | The chat completion workspace unique identifier (uid) |

### Request body

```json
{
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "user",
      "content": "What are the main features of Meilisearch?"
    }
  ],
  "stream": true
}
```

| Name           | Type    | Required | Description                                                                  |
| :------------- | :------ | :------- | :--------------------------------------------------------------------------- |
| **`model`**    | String  | Yes      | Model to use and will be related to the source LLM in the workspace settings |
| **`messages`** | Array   | Yes      | Array of message objects with `role` and `content`                           |
| **`stream`**   | Boolean | No       | Enable streaming responses. Must be `true` if specified                                 |

<Warning>
Meilisearch chat completions only supports streaming responses (`stream: true`).
</Warning>

### Message object

| Name          | Type   | Description                                                |
| :------------ | :----- | :--------------------------------------------------------- |
| **`role`**    | String | Message role: `"system"`, `"user"`, or `"assistant"`       |
| **`content`** | String | Message content                                            |

### Response

The response follows the OpenAI chat completions format. For streaming responses, the endpoint returns Server-Sent Events (SSE).

#### Streaming response example

```
data: {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1677652288,"model":"gpt-3.5-turbo","choices":[{"index":0,"delta":{"content":"Meilisearch"},"finish_reason":null}]}

data: {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1677652288,"model":"gpt-3.5-turbo","choices":[{"index":0,"delta":{"content":" is"},"finish_reason":null}]}

data: {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1677652288,"model":"gpt-3.5-turbo","choices":[{"index":0,"delta":{},"finish_reason":"stop"}]}

data: [DONE]
```

### Example

<CodeGroup>

```bash cURL
curl -N \
  -X POST 'http://localhost:7700/chats/customer-support/chat/completions' \
  -H 'Authorization: Bearer DEFAULT_CHAT_KEY' \
  -H 'Content-Type: application/json' \
  --data-binary '{
    "model": "gpt-3.5-turbo",
    "messages": [
      {
        "role": "user",
        "content": "What is Meilisearch?"
      }
    ],
    "stream": true
  }'
```

```javascript Javascript OpenAI SDK
import OpenAI from 'openai';

const client = new OpenAI({
  baseURL: 'http://localhost:7700/chats/customer-support',
  apiKey: 'DEFAULT_CHAT_KEY',
});

const stream = await client.chat.completions.create({
  model: 'gpt-3.5-turbo',
  messages: [{ role: 'user', content: 'What is Meilisearch?' }],
  stream: true,
});

for await (const chunk of stream) {
  console.log(chunk.choices[0]?.delta?.content || '');
}
```

```python Python OpenAI SDK
from openai import OpenAI

client = OpenAI(
    base_url="http://localhost:7700/chats/customer-support",
    api_key="DEFAULT_CHAT_KEY"
)

stream = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[{"role": "user", "content": "What is Meilisearch?"}],
    stream=True,
)

for chunk in stream:
    if chunk.choices[0].delta.content is not None:
        print(chunk.choices[0].delta.content, end="")
```

</CodeGroup>
