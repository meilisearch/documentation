---
title: Chats
sidebarTitle: Chats
description: The /chats route allows you to create conversational search experiences using LLM technology
---

import { RouteHighlighter } from '/snippets/route_highlighter.mdx';
import { Warning } from '/snippets/notice_tag.mdx'

The `/chats` route enables AI-powered conversational search by integrating Large Language Models (LLMs) with your Meilisearch data. This feature allows users to ask questions in natural language and receive contextual answers based on your indexed content.

<Note>
This is an experimental feature. Use the Meilisearch Cloud UI or the experimental features endpoint to activate it:

```sh
curl \
  -X PATCH 'MEILISEARCH_URL/experimental-features/' \
  -H 'Content-Type: application/json' \
  --data-binary '{
    "chatCompletions": true
  }'
```
</Note>

## Chat completions workspace object

```json
{
  "uid": "customer-support"
}
```

| Name        | Type   | Description                                         |
| :---------- | :----- | :-------------------------------------------------- |
| **`uid`**   | String | Unique identifier for the chat completions workspace |

## Update the chat workspace settings

<RouteHighlighter method="PATCH" path="/chats/{workspace}/settings" />

Configure the LLM provider and settings for a chat workspace.

```json
{
  "source": "openAi",
  "orgId": null,
  "projectId": null,
  "apiVersion": null,
  "deploymentId": null,
  "baseUrl": null,
  "apiKey": "sk-abc...",
  "prompts": {
    "system": "You are a helpful assistant that answers questions based on the provided context."
  }
}
```

### Path parameters

| Name            | Type   | Description                          |
| :-------------- | :----- | :----------------------------------- |
| **`workspace`** | String | The workspace identifier             |

### Settings parameters

| Name              | Type   | Description                                                                   |
| :---------------- | :----- | :---------------------------------------------------------------------------- |
| **`source`**      | String | LLM source: `"openAi"`, `"azureOpenAi"`, `"mistral"`, `"gemini"`, or `"vLlm"` |
| **`orgId`**       | String | Organization ID for the LLM provider (required for azureOpenAi)               |
| **`projectId`**   | String | Project ID for the LLM provider                                               |
| **`apiVersion`**  | String | API version for the LLM provider (required for azureOpenAi)                   |
| **`deploymentId`**| String | Deployment ID for the LLM provider (required for azureOpenAi)                 |
| **`baseUrl`**     | String | Base URL for the provider (required for azureOpenAi and vLlm)                 |
| **`apiKey`**      | String | API key for the LLM provider (optional for vLlm)                              |
| **`prompts`**     | Object | Prompts object containing system prompts and other configuration              |

### The prompts object

| Name                      | Type   | Description                                                       |
| :------------------------ | :----- | :---------------------------------------------------------------- |
| **`system`**              | String | A prompt added to the start of the conversation to guide the LLM  |
| **`searchDescription`**   | String | A prompt to explain what the internal search function does        |
| **`searchQParam`**        | String | A prompt to explain what the `q` parameter of the search function does and how to use it |
| **`searchIndexUidParam`** | String | A prompt to explain what the `indexUid` parameter of the search function does and how to use it |


### Request body

```json
{
  "source": "openAi",
  "apiKey": "sk-...",
  "prompts": {
    "system": "You are a helpful assistant."
  }
}
```

All fields are optional. Only provided fields will be updated.

### Response: `200 OK`

Returns the updated settings object. Note that `apiKey` is write-only and will not be returned in the response.

### Examples

<CodeGroup>

```bash openAi
curl \
  -X PATCH 'http://localhost:7700/chats/customer-support/settings' \
  -H 'Authorization: Bearer MASTER_KEY' \
  -H 'Content-Type: application/json' \
  --data-binary '{
    "source": "openAi",
    "apiKey": "sk-abc...",
    "prompts": {
      "system": "You are a helpful customer support assistant."
    }
  }'
```

```bash azureOpenAi
curl \
  -X PATCH 'http://localhost:7700/chats/customer-support/settings' \
  -H 'Authorization: Bearer MASTER_KEY' \
  -H 'Content-Type: application/json' \
  --data-binary '{
    "source": "azureOpenAi",
    "orgId": "your-azure-org-id",
    "apiVersion": "your-api-version",
    "deploymentId": "your-deployment-id",
    "apiKey": "your-azure-api-key",
    "baseUrl": "https://your-resource.openai.azure.com",
    "prompts": {
      "system": "You are a helpful customer support assistant."
    }
  }'
```

```bash mistral
curl \
  -X PATCH 'http://localhost:7700/chats/customer-support/settings' \
  -H 'Authorization: Bearer MASTER_KEY' \
  -H 'Content-Type: application/json' \
  --data-binary '{
    "source": "mistral",
    "apiKey": "your-mistral-api-key",
    "prompts": {
      "system": "You are a helpful customer support assistant."
    }
  }'
```

```bash gemini
curl \
  -X PATCH 'http://localhost:7700/chats/customer-support/settings' \
  -H 'Authorization: Bearer MASTER_KEY' \
  -H 'Content-Type: application/json' \
  --data-binary '{
    "source": "gemini",
    "apiKey": "your-gemini-api-key",
    "prompts": {
      "system": "You are a helpful customer support assistant."
    }
  }'
```

```bash vLlm
curl \
  -X PATCH 'http://localhost:7700/chats/customer-support/settings' \
  -H 'Authorization: Bearer MASTER_KEY' \
  -H 'Content-Type: application/json' \
  --data-binary '{
    "source": "vLlm",
    "baseUrl": "http://your-vllm-server:8000",
    "prompts": {
      "system": "You are a helpful customer support assistant."
    }
  }'
```

</CodeGroup>

## Chat completions

<RouteHighlighter method="POST" path="/chats/{workspace}/chat/completions" />

Create a chat completion using the OpenAI-compatible interface. The endpoint searches relevant indexes and generates responses based on the retrieved content.

### Path parameters

| Name            | Type   | Description                                           |
| :-------------- | :----- | :---------------------------------------------------- |
| **`workspace`** | String | The chat completion workspace unique identifier (uid) |

### Request body

```json
{
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "user",
      "content": "What are the main features of Meilisearch?"
    }
  ],
  "stream": true
}
```

| Name           | Type    | Required | Description                                                                  |
| :------------- | :------ | :------- | :--------------------------------------------------------------------------- |
| **`model`**    | String  | Yes      | Model to use and will be related to the source LLM in the workspace settings |
| **`messages`** | Array   | Yes      | Array of message objects with `role` and `content`                           |
| **`stream`**   | Boolean | No       | Enable streaming responses (default: `true`)                                 |

<Warning>
Currently, only streaming responses (`stream: true`) are supported. Non-streaming responses will be available in a future release.
</Warning>

### Message object

| Name          | Type   | Description                                                |
| :------------ | :----- | :--------------------------------------------------------- |
| **`role`**    | String | Message role: `"system"`, `"user"`, or `"assistant"`       |
| **`content`** | String | Message content                                            |

### Response

The response follows the OpenAI chat completions format. For streaming responses, the endpoint returns Server-Sent Events (SSE).

#### Streaming response example

```
data: {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1677652288,"model":"gpt-3.5-turbo","choices":[{"index":0,"delta":{"content":"Meilisearch"},"finish_reason":null}]}

data: {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1677652288,"model":"gpt-3.5-turbo","choices":[{"index":0,"delta":{"content":" is"},"finish_reason":null}]}

data: {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1677652288,"model":"gpt-3.5-turbo","choices":[{"index":0,"delta":{},"finish_reason":"stop"}]}

data: [DONE]
```

### Example

<CodeGroup>

```bash cURL
curl \
  -X POST 'http://localhost:7700/chats/customer-support/chat/completions' \
  -H 'Authorization: Bearer DEFAULT_CHAT_KEY' \
  -H 'Content-Type: application/json' \
  --data-binary '{
    "model": "gpt-3.5-turbo",
    "messages": [
      {
        "role": "user",
        "content": "What is Meilisearch?"
      }
    ],
    "stream": true
  }'
```

```javascript Javascript OpenAI SDK
import OpenAI from 'openai';

const client = new OpenAI({
  baseURL: 'http://localhost:7700/chats/customer-support',
  apiKey: 'DEFAULT_CHAT_KEY',
});

const stream = await client.chat.completions.create({
  model: 'gpt-3.5-turbo',
  messages: [{ role: 'user', content: 'What is Meilisearch?' }],
  stream: true,
});

for await (const chunk of stream) {
  console.log(chunk.choices[0]?.delta?.content || '');
}
```

```python Python OpenAI SDK
from openai import OpenAI

client = OpenAI(
    base_url="http://localhost:7700/chats/customer-support",
    api_key="DEFAULT_CHAT_KEY"
)

stream = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[{"role": "user", "content": "What is Meilisearch?"}],
    stream=True,
)

for chunk in stream:
    if chunk.choices[0].delta.content is not None:
        print(chunk.choices[0].delta.content, end="")
```

</CodeGroup>

## Get chat settings

<RouteHighlighter method="GET" path="/chats/{workspace}/settings" />

Retrieve the current settings for a chat workspace.

### Path parameters

| Name            | Type   | Description                          |
| :-------------- | :----- | :----------------------------------- |
| **`workspace`** | String | The workspace identifier             |

### Response: `200 OK`

Returns the settings object without the `apiKey` field.

```json
{
  "source": "openAi",
  "prompts": {
    "system": "You are a helpful assistant."
  }
}
```

### Example

<CodeGroup>

```bash cURL
curl \
  -X GET 'http://localhost:7700/chats/customer-support/settings' \
  -H 'Authorization: Bearer MASTER_KEY'
```

</CodeGroup>

## List chat workspaces

<RouteHighlighter method="GET" path="/chats" />

List all available chat workspaces. Results can be paginated using query parameters.

### Query parameters

| Query parameter | Description                    | Default value |
| :-------------- | :----------------------------- | :------------ |
| **`offset`**    | Number of workspaces to skip   | `0`           |
| **`limit`**     | Number of workspaces to return | `20`          |

### Response

| Name          | Type    | Description                               |
| :------------ | :------ | :---------------------------------------- |
| **`results`** | Array   | An array of chat workspace objects        |
| **`offset`**  | Integer | Number of workspaces skipped              |
| **`limit`**   | Integer | Number of workspaces returned             |
| **`total`**   | Integer | Total number of workspaces                |

### Example

<CodeGroup>

```bash cURL
curl \
  -X GET 'http://localhost:7700/chats?limit=10' \
  -H 'Authorization: Bearer MASTER_KEY'
```

</CodeGroup>

#### Response: `200 OK`

```json
{
  "results": [
    {
      "uid": "customer-support"
    },
    {
      "uid": "internal-docs"
    }
  ],
  "offset": 0,
  "limit": 10,
  "total": 2
}
```

## Authentication

The chat feature integrates with Meilisearch's authentication system:

- **Default Chat API Key**: A new default key is created when chat is enabled, with permissions to access chat endpoints
- **Tenant tokens**: Fully supported for multi-tenant applications
- **Index visibility**: Chat searches only indexes accessible with the provided API key

## Tool calling

The chat feature uses internal tool calling to search your indexes.
But there are a bunch of tools that are automatically invoked based on the user's questions:

- `_meiliSearchProgress`: Reports search progress
- `_meiliAppendConversationMessage`: Maintains conversation context
- `_meiliSearchSources`: Displays source documents used in responses

You must declare those tools when using the chat completion API to have the best experience.
